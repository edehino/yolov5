{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## these are the additional packages needed\n",
    "# !python -m pip install --upgrade pip\n",
    "# !pip install tensorflow==2.5\n",
    "# !pip install tensorboard==2.8\n",
    "# !pip install torch\n",
    "# !pip install wandb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d17caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #for yolov5 implemented in pytorch\n",
    "from IPython.display import Image #for rendering predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df336f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images are :  640\n",
      "Validation images are :  160\n"
     ]
    }
   ],
   "source": [
    "## Divide the dataset into train, val, and test folder\n",
    "import os\n",
    "from random import choice\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "imgs = []\n",
    "annots = []\n",
    "\n",
    "## CHANGE DIRECTORY ACCORDING TO YOUR SETUP\n",
    "# directory names\n",
    "main_path = \"C:/Users/Pinky/Documents/Architectures/YOLOv5/yolov5\"\n",
    "trainPath = main_path + \"/dataset/images/train\"\n",
    "valPath = main_path + \"/dataset/images/val\"\n",
    "datasetPath = main_path + \"/dataset/data\"\n",
    "\n",
    "# train-val-test ratio\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.20\n",
    "\n",
    "\n",
    "# count total number of images in the dataset directory\n",
    "totalImageCount = len(os.listdir(datasetPath))/2\n",
    "\n",
    "# sort the image files from the txt/annotation files\n",
    "for (dirname, dirs, files) in os.walk(datasetPath):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):\n",
    "            annots.append(filename)\n",
    "        else:\n",
    "            imgs.append(filename)\n",
    "\n",
    "# count and display number of images for train and val\n",
    "train_count = int(len(imgs)*train_ratio)\n",
    "val_count = int(len(imgs)*val_ratio)\n",
    "print(\"training images are : \",train_count)\n",
    "print(\"Validation images are : \",val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de49c028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "## CHANGE DIRECTORY ACCORDING TO YOUR SETUP\n",
    "trainimagePath = main_path + \"/dataset/images/train\"\n",
    "trainlabelPath = main_path + \"/dataset/labels/train\"\n",
    "valimagePath = main_path + \"/dataset/images/val\"\n",
    "vallabelPath = main_path + \"/dataset/labels/val\"\n",
    "\n",
    "# delete images and labels folder\n",
    "shutil.rmtree(main_path + \"/dataset/images\")\n",
    "shutil.rmtree(main_path + \"/dataset/labels\")\n",
    "\n",
    "# create images and labels folder\n",
    "os.chdir(main_path + \"/dataset\")\n",
    "Path(\"images/train\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"images/val\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"labels/train\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"labels/val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# randomly select train images\n",
    "for x in range(train_count):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(datasetPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(datasetPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "\n",
    "\n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    annots.remove(fileXml)\n",
    "    \n",
    "# the remaining images will be validation images\n",
    "for x in range(len(imgs)):\n",
    "    shutil.copy(os.path.join(datasetPath, imgs[x]), os.path.join(valimagePath, imgs[x]))\n",
    "    shutil.copy(os.path.join(datasetPath, annots[x]), os.path.join(vallabelPath, annots[x]))\n",
    "\n",
    "# remove the holder lists\n",
    "imgs=[]\n",
    "annots=[]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b5157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 300 --batch 16 --epochs 30 --data dataset.yaml --weights yolov5s.pt --cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
